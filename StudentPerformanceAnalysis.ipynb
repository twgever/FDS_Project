{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **FDS project, winter semester 2023**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tommaso Leonardi, Arianna Paolini, Stefano Saravalle, Paolo Cursi, Pietro Signorino\n",
    "<leonardi.1914546@studenti.uniroma1.it>, <paolini.1943164@studenti.uniroma1.it>, <saravalle.1948684@studenti.uniroma1.it>, <paoloc1999@gmail.com>, <signorino.2149741@studenti.uniroma1.it>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Student Performance Analysis & Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset tables\n",
    "courses = pd.read_csv('./data/courses.csv')  #22 rows for courses (modules) and their presentations\n",
    "assess = pd.read_csv('./data/assessments.csv')  #206 rows of assessments for module-presentations (including the final exam)\n",
    "results = pd.read_csv('./data/studentAssessment.csv') #173,912 rows for the scores obtained by students in the asssesments\n",
    "studs = pd.read_csv('./data/studentInfo.csv') #32,593 rows for demographic information on students and their results in module-presentations\n",
    "registr = pd.read_csv('./data/studentRegistration.csv') #32,593 rows for student registration/unregistration on module-presentations\n",
    "vle = pd.read_csv('./data/studentVle.csv') #10,655,280 rows for daily student interactions with online resources for a module-presentation\n",
    "materials = pd.read_csv('./data/vle.csv') #6,364 rows for the materials available on the Virtual Learning Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _Open University Learning Analytics dataset_ that we are considering has the following structure: \n",
    "\n",
    " <img src=\"https://analyse.kmi.open.ac.uk/resources/images/model.png\" alt=\"dataset structure\" style=\"height: 500px; width:500px;\"/>\n",
    "\n",
    "\n",
    "(https://analyse.kmi.open.ac.uk/open_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DONE: definire i task -> regressione/classificazione dello score per ogni assessment\n",
    "#DONE: trasformare valori categorici in numeri\n",
    "#DONE: normalizzare i dati\n",
    "#TODO: pulire i dati\n",
    "#TODO: mostrare la distribuzione dei dati con grafici\n",
    "#TODO: fare split tra training e test set (considerare cross validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our goal is to predict the score of each student in any assessment belonging to a specific module presentation, we consider the demographic information about students (from the table *studentInfo*) and their accessess to online resources in the Virtual Learning Environment (VLE) for each course (from the tables *studentVle* and *vle*) as features for our models. \n",
    "\n",
    "We also take in account the assessment type and weigth (from the table *assessments*) and the time the student spent before submitting it (from the table *studentAssessment*). \n",
    "\n",
    "The target value to predict is the score from the *studentAssessment* table, which ranges from 0 to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163387, 33)\n"
     ]
    }
   ],
   "source": [
    "#dropping some features\n",
    "studs = studs.drop(\"final_result\", axis=1)\n",
    "registr = registr.drop(\"date_unregistration\", axis=1)\n",
    "materials = materials.drop([\"week_from\", \"week_to\"], axis=1)\n",
    "vle = vle.drop(\"date\", axis=1)\n",
    "results = results.drop(\"is_banked\", axis=1)\n",
    "\n",
    "#remove Nan values in studs 'imd_band' (amounts to around 7000 total assessment results)\n",
    "studs=studs.dropna()\n",
    "\n",
    "#remove students with 'date registration' that is null (amounts to 7 total assessment results)\n",
    "registr=registr.dropna()\n",
    "\n",
    "#match info about a student and his date of registration to a module presentation\n",
    "studs = studs.merge(registr, how=\"inner\", on=[\"code_module\", \"code_presentation\",\"id_student\"])\n",
    "\n",
    "#match a student's interactions with an online resource with the type of the resource\n",
    "vle = vle.merge(materials, how=\"inner\", on=[\"code_module\", \"code_presentation\",\"id_site\"] )\n",
    "vle = vle.drop(\"id_site\", axis=1)\n",
    "\n",
    "#group the interactions by resource type and add a feature to consider the total sum of clicks for each resource type\n",
    "temp = vle.groupby([\"code_module\", \"code_presentation\", \"id_student\", \"activity_type\"]).sum().reset_index()\n",
    "for x in temp[\"activity_type\"].unique():\n",
    "    temp[x+\"_clicks\"] = np.where(temp[\"activity_type\"]==x, temp[\"sum_click\"], 0)\n",
    "temp = temp.drop([\"activity_type\",\"sum_click\"], axis=1)\n",
    "temp = temp.groupby([\"code_module\", \"code_presentation\", \"id_student\"]).sum().reset_index()\n",
    "\n",
    "#match student's information with his interactions on the VLE for a specific module presentation and fill nan with 0\n",
    "studs = studs.merge(temp, how=\"left\", on=[\"code_module\", \"code_presentation\", \"id_student\"])\n",
    "studs= studs.fillna(0)\n",
    "\n",
    "#remove assessments without 'date'=nan and results with 'score'=nan\n",
    "assess=assess.dropna()\n",
    "results=results.dropna()\n",
    "#a=results.merge(assess[assess['date'].isnull()], how=\"inner\", on=[\"id_assessment\"]) #only 2865 instances are removed\n",
    "\n",
    "#match assessments with students scores\n",
    "assess = assess.merge(results, how=\"inner\", on=\"id_assessment\")\n",
    "\n",
    "#substitute date in assessment and date_submitted in results with their difference (to be considered as a time delay from expected submission)\n",
    "assess[\"submission_delay\"] = assess[\"date_submitted\"] - assess[\"date\"] #\"date\" is the deadline for the assessment\n",
    "assess = assess.drop([\"date\",\"date_submitted\"], axis=1)\n",
    "\n",
    "#match students with their results\n",
    "df = studs.merge(assess, how=\"inner\", on=[\"code_module\", \"code_presentation\",\"id_student\"])\n",
    "\n",
    "#remove ids from the features\n",
    "df = df.drop([\"code_module\",\"code_presentation\",\"id_student\",\"id_assessment\"], axis=1) #163387 total rows\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the features in the dataset have *string* values (eg. 'gender' has values {'M', 'F'}). \n",
    "\n",
    "We convert those features to integer values. The list *to_be_converted* contains the names of such features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values in 'gender' column: {'F', 'M'}\n",
      "Mapping from string values to numerical using the following dictionary: {'F': 0, 'M': 1}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Values in 'region' column: {'North Western Region', 'Wales', 'South East Region', 'East Midlands Region', 'Yorkshire Region', 'Ireland', 'South West Region', 'East Anglian Region', 'London Region', 'Scotland', 'South Region', 'North Region', 'West Midlands Region'}\n",
      "Mapping from string values to numerical using the following dictionary: {'North Western Region': 0, 'Wales': 1, 'South East Region': 2, 'East Midlands Region': 3, 'Yorkshire Region': 4, 'Ireland': 5, 'South West Region': 6, 'East Anglian Region': 7, 'London Region': 8, 'Scotland': 9, 'South Region': 10, 'North Region': 11, 'West Midlands Region': 12}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Values in 'disability' column: {'Y', 'N'}\n",
      "Mapping from string values to numerical using the following dictionary: {'Y': 0, 'N': 1}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Values in 'assessment_type' column: {'TMA', 'Exam', 'CMA'}\n",
      "Mapping from string values to numerical using the following dictionary: {'TMA': 0, 'Exam': 1, 'CMA': 2}\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[\"highest_education\"] = df[\"highest_education\"].replace({\"No Formal quals\":0, \"Lower Than A Level\":1, \"A Level or Equivalent\": 2, \n",
    "                                                           \"HE Qualification\":3, \"Post Graduate Qualification\":4 })\n",
    "\n",
    "df[\"imd_band\"] = df[\"imd_band\"].replace({\"0-10%\":0, \"10-20\":1, \"20-30%\": 2, \"30-40%\":3, \"40-50%\":4, \"50-60%\":5,\n",
    "                                          \"60-70%\":6, \"70-80%\":7, \"80-90%\":8, \"90-100%\":9 })\n",
    "\n",
    "df[\"age_band\"] = df[\"age_band\"].replace({\"0-35\":0, \"35-55\":1, \"55<=\": 2})\n",
    "\n",
    "to_be_converted = [\"gender\", \"region\", \"disability\", \"assessment_type\"]\n",
    "\n",
    "for column_name in to_be_converted:\n",
    "\n",
    "    values = set(df[column_name].tolist())\n",
    "    print(f\"Values in '{column_name}' column: {values}\")\n",
    "\n",
    "    mapping = {x : y for y,x in enumerate(values)}\n",
    "    print(f\"Mapping from string values to numerical using the following dictionary: {mapping}\")\n",
    "\n",
    "    df[column_name] = df[column_name].map(mapping)\n",
    "\n",
    "    print(\"\\n==================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the previous step we now have a dataset containing only *integer values*.\n",
    "\n",
    "We normalize every feature $f$ with values $vals$ and\n",
    "- maximum value:  $max$\n",
    "- minimum value:  $min$\n",
    "\n",
    "with the following algorithm.\n",
    "\n",
    "For each $v \\in vals$:\n",
    "$$\n",
    "v := \\frac{v - min}{max - min}\n",
    "$$\n",
    "\n",
    "This step ensures that every value in the dataset is in the range $[0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n",
      "Normalizing column 'gender' with values between -0.5284630968192083 and 0.47153690318079167\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.5284630968192083 1.0 0.0\n",
      "region\n",
      "Normalizing column 'region' with values between -6.15382496771469 and 5.84617503228531\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.5128187473095576 1.0 0.0\n",
      "highest_education\n",
      "Normalizing column 'highest_education' with values between -1.78410155030694 and 2.21589844969306\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.446025387576735 1.0 0.0\n",
      "imd_band\n",
      "Normalizing column 'imd_band' with values between -4.423577151180939 and 4.576422848819061\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.4915085723534377 1.0 0.0\n",
      "age_band\n",
      "Normalizing column 'age_band' with values between -0.3176752128382307 and 1.6823247871617693\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.15883760641911535 1.0 0.0\n",
      "num_of_prev_attempts\n",
      "Normalizing column 'num_of_prev_attempts' with values between -0.14701904068255126 and 5.852980959317449\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.02450317344709187 1.0 0.0\n",
      "studied_credits\n",
      "Normalizing column 'studied_credits' with values between -46.702767050010095 and 553.2972329499898\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.0778379450833502 1.0 0.0\n",
      "disability\n",
      "Normalizing column 'disability' with values between -0.9097847441962947 and 0.09021525580370526\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.9097847441962947 1.0 0.0\n",
      "date_registration\n",
      "Normalizing column 'date_registration' with values between -244.60039048394304 and 233.39960951605696\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.5117162980835628 1.0 0.0\n",
      "forumng_clicks\n",
      "Normalizing column 'forumng_clicks' with values between -384.22073971613406 and 12769.779260283865\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.02920942220739958 1.0 0.0\n",
      "homepage_clicks\n",
      "Normalizing column 'homepage_clicks' with values between -328.22352451541434 and 6948.776475484586\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.04510423588228862 1.0 0.0\n",
      "oucontent_clicks\n",
      "Normalizing column 'oucontent_clicks' with values between -557.9380489267812 and 8596.06195107322\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.06095019105601717 1.0 0.0\n",
      "resource_clicks\n",
      "Normalizing column 'resource_clicks' with values between -48.185816497028526 and 5098.814183502972\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.009361922769968627 1.0 0.0\n",
      "subpage_clicks\n",
      "Normalizing column 'subpage_clicks' with values between -169.93014132091292 and 4175.069858679087\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.03910935358363934 1.0 0.0\n",
      "url_clicks\n",
      "Normalizing column 'url_clicks' with values between -26.228188289153973 and 2107.771811710846\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.012290622441028104 1.0 0.0\n",
      "dataplus_clicks\n",
      "Normalizing column 'dataplus_clicks' with values between -3.075434398085527 and 139.92456560191448\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.021506534252346343 1.0 0.0\n",
      "glossary_clicks\n",
      "Normalizing column 'glossary_clicks' with values between -3.812843127054172 and 2948.1871568729457\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.0012916135254248551 1.0 0.0\n",
      "oucollaborate_clicks\n",
      "Normalizing column 'oucollaborate_clicks' with values between -4.192922325521614 and 311.80707767447836\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.013268741536460803 1.0 0.0\n",
      "quiz_clicks\n",
      "Normalizing column 'quiz_clicks' with values between -364.695667341955 and 10752.304332658045\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.03280522329243096 1.0 0.0\n",
      "ouelluminate_clicks\n",
      "Normalizing column 'ouelluminate_clicks' with values between -2.415614461370856 and 314.58438553862914\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.0076202348939143705 1.0 0.0\n",
      "sharedsubpage_clicks\n",
      "Normalizing column 'sharedsubpage_clicks' with values between -0.0092663430995122 and 5.990733656900487\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.0015443905165853668 1.0 0.0\n",
      "questionnaire_clicks\n",
      "Normalizing column 'questionnaire_clicks' with values between -3.919816142043125 and 85.08018385795688\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.044042878000484544 1.0 0.0\n",
      "page_clicks\n",
      "Normalizing column 'page_clicks' with values between -3.39855680072466 and 330.60144319927537\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.010175319762648682 1.0 0.0\n",
      "externalquiz_clicks\n",
      "Normalizing column 'externalquiz_clicks' with values between -2.949408459669374 and 337.05059154033063\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.008674730763733452 1.0 0.0\n",
      "ouwiki_clicks\n",
      "Normalizing column 'ouwiki_clicks' with values between -32.83320582420878 and 2084.1667941757914\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.015509308372323465 1.0 0.0\n",
      "dualpane_clicks\n",
      "Normalizing column 'dualpane_clicks' with values between -1.1076952266704205 and 66.89230477332958\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.016289635686329716 1.0 0.0\n",
      "folder_clicks\n",
      "Normalizing column 'folder_clicks' with values between -0.3694418772607368 and 12.630558122739263\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.0284186059431336 1.0 0.0\n",
      "repeatactivity_clicks\n",
      "Normalizing column 'repeatactivity_clicks' with values between -0.0005141167901975065 and 3.9994858832098026\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.00012852919754937663 1.0 0.0\n",
      "htmlactivity_clicks\n",
      "Normalizing column 'htmlactivity_clicks' with values between -0.465587837465649 and 32.53441216253435\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.01410872234744391 1.0 0.0\n",
      "assessment_type\n",
      "Normalizing column 'assessment_type' with values between -0.8366210286008067 and 1.1633789713991933\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.41831051430040334 1.0 0.0\n",
      "weight\n",
      "Normalizing column 'weight' with values between -11.208211179592011 and 88.79178882040799\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.11208211179592013 1.0 0.0\n",
      "score\n",
      "Normalizing column 'score' with values between -75.79784805400675 and 24.20215194599325\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.7579784805400676 1.0 0.0\n",
      "submission_delay\n",
      "Normalizing column 'submission_delay' with values between -229.38315777877065 and 388.6168422212294\n",
      "\n",
      "==================================================\n",
      "\n",
      "0.3711701582180755 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "\n",
    "    col_max = df[col].max()\n",
    "    col_min = df[col].min()\n",
    "\n",
    "    print(f\"Normalizing column '{col}' with values between {col_min} and {col_max}\")\n",
    "    print(\"\\n==================================================\\n\")\n",
    "\n",
    "    df[col] = (df[col] - col_min) / (col_max - col_min)\n",
    "    print(df[col].mean(),df[col].max(),df[col].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
