{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **FDS project, winter semester 2023**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tommaso Leonardi, Arianna Paolini, Stefano Saravalle, Paolo Cursi, Pietro Signorino\n",
    "<leonardi.1914546@studenti.uniroma1.it>, <paolini.1943164@studenti.uniroma1.it>, <saravalle.1948684@studenti.uniroma1.it>, <paoloc1999@gmail.com>, <signorino.2149741@studenti.uniroma1.it>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Student Performance Analysis & Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset tables\n",
    "courses = pd.read_csv('./data/courses.csv')  #22 rows for courses (modules) and their presentations\n",
    "assess = pd.read_csv('./data/assessments.csv')  #206 rows of assessments for module-presentations (including the final exam)\n",
    "results = pd.read_csv('./data/studentAssessment.csv') #173,912 rows for the scores obtained by students in the asssesments\n",
    "studs = pd.read_csv('./data/studentInfo.csv') #32,593 rows for demographic information on students and their results in module-presentations\n",
    "registr = pd.read_csv('./data/studentRegistration.csv') #32,593 rows for student registration/unregistration on module-presentations\n",
    "vle = pd.read_csv('./data/studentVle.csv') #10,655,280 rows for daily student interactions with online resources for a module-presentation\n",
    "materials = pd.read_csv('./data/vle.csv') #6,364 rows for the materials available on the Virtual Learning Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _Open University Learning Analytics dataset_ that we are considering has the following structure: \n",
    "\n",
    " <img src=\"https://analyse.kmi.open.ac.uk/resources/images/model.png\" alt=\"dataset structure\" style=\"height: 500px; width:500px;\"/>\n",
    "\n",
    "\n",
    "(https://analyse.kmi.open.ac.uk/open_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DONE: definire i task -> regressione/classificazione dello score per ogni assessment\n",
    "#DONE: trasformare valori categorici in numeri\n",
    "#DONE: normalizzare i dati\n",
    "#TODO: pulire i dati\n",
    "#TODO: mostrare la distribuzione dei dati con grafici\n",
    "#TODO: fare split tra training e test set (considerare cross validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our goal is to predict the score of each student in any assessment belonging to a specific module presentation, we consider the demographic information about students (from the table *studentInfo*) and their accessess to online resources in the Virtual Learning Environment (VLE) for each course (from the tables *studentVle* and *vle*) as features for our models. \n",
    "\n",
    "We also take in account the assessment type and weigth (from the table *assessments*) and the time the student spent before submitting it (from the table *studentAssessment*). \n",
    "\n",
    "The target value to predict is the score from the *studentAssessment* table, which ranges from 0 to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping some features\n",
    "studs = studs.drop(\"final_result\", axis=1)\n",
    "registr = registr.drop(\"date_unregistration\", axis=1)\n",
    "materials = materials.drop([\"week_from\", \"week_to\"], axis=1)\n",
    "vle = vle.drop(\"date\", axis=1)\n",
    "results = results.drop(\"is_banked\", axis=1)\n",
    "\n",
    "#match info about a student and his date of registration to a module presentation\n",
    "studs = studs.merge(registr, how=\"inner\", on=[\"code_module\", \"code_presentation\",\"id_student\"])\n",
    "\n",
    "#match a student's interactions with an online resource with the type of the resource\n",
    "vle = vle.merge(materials, how=\"inner\", on=[\"code_module\", \"code_presentation\",\"id_site\"] )\n",
    "vle = vle.drop(\"id_site\", axis=1)\n",
    "\n",
    "#group the interactions by resource type and add a feature to consider the total sum of clicks for each resource type\n",
    "temp = vle.groupby([\"code_module\", \"code_presentation\", \"id_student\", \"activity_type\"]).sum().reset_index()\n",
    "for x in temp[\"activity_type\"].unique():\n",
    "    temp[x+\"_clicks\"] = np.where(temp[\"activity_type\"]==x, temp[\"sum_click\"], 0)\n",
    "temp = temp.drop([\"activity_type\",\"sum_click\"], axis=1)\n",
    "temp = temp.groupby([\"code_module\", \"code_presentation\", \"id_student\"]).sum().reset_index()\n",
    "\n",
    "#match student's information with his interactions on the VLE for a specific module presentation\n",
    "studs = studs.merge(temp, how=\"inner\", on=[\"code_module\", \"code_presentation\", \"id_student\"])\n",
    "\n",
    "#match assessments with students scores\n",
    "assess = assess.merge(results, how=\"inner\", on=\"id_assessment\")\n",
    "\n",
    "#substitute date in assessment and date_submitted in results with their difference (to be considered as a time interval)\n",
    "assess[\"submission_interval\"] = assess[\"date\"] - assess[\"date_submitted\"] #\"date\" is the deadline for the assessment\n",
    "assess = assess.drop([\"date\",\"date_submitted\"], axis=1)\n",
    "\n",
    "#match students with their results\n",
    "df = studs.merge(assess, how=\"inner\", on=[\"code_module\", \"code_presentation\",\"id_student\"])\n",
    "\n",
    "#remove ids from the features\n",
    "df = df.drop([\"code_module\",\"code_presentation\",\"id_student\",\"id_assessment\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the features in the dataset have *string* values (eg. 'gender' has values {'M', 'F'}). \n",
    "\n",
    "We convert those features to integer values. The list *to_be_converted* contains the names of such features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_converted = [\"gender\", \"region\", \"highest_education\", \"imd_band\", \"age_band\", \"disability\", \"assessment_type\"]\n",
    "\n",
    "for column_name in to_be_converted:\n",
    "\n",
    "    values = set(df[column_name].tolist())\n",
    "    print(f\"Values in '{column_name}' column: {values}\")\n",
    "\n",
    "    mapping = {x : y for y,x in enumerate(values)}\n",
    "    print(f\"Mapping from string values to numerical using the following dictionary: {mapping}\")\n",
    "\n",
    "    df[column_name] = df[column_name].map(mapping)\n",
    "\n",
    "    print(\"\\n==================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the previous step we now have a dataset containing only *integer values*.\n",
    "\n",
    "We normalize every feature $f$ with values $vals$ and\n",
    "- maximum value:  $max$\n",
    "- minimum value:  $min$\n",
    "\n",
    "with the following algorithm.\n",
    "\n",
    "For each $v \\in vals$:\n",
    "$$\n",
    "v := \\frac{v - min}{max - min}\n",
    "$$\n",
    "\n",
    "This step ensures that every value in the dataset is in the range $[0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df:\n",
    "    col_max = df[col].max()\n",
    "    col_min = df[col].min()\n",
    "\n",
    "    print(f\"Normalizing column '{col}' with values between {col_min} and {col_max}\")\n",
    "    print(\"\\n==================================================\\n\")\n",
    "\n",
    "    df[col] = (df[col] - col_min) / (col_max - col_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
