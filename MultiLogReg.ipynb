{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model as skm\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gender', 'region', 'highest_education', 'imd_band', 'age_band',\n",
      "       'num_of_prev_attempts', 'studied_credits', 'disability',\n",
      "       'date_registration', 'forumng_clicks', 'homepage_clicks',\n",
      "       'oucontent_clicks', 'resource_clicks', 'subpage_clicks', 'url_clicks',\n",
      "       'dataplus_clicks', 'glossary_clicks', 'oucollaborate_clicks',\n",
      "       'quiz_clicks', 'ouelluminate_clicks', 'sharedsubpage_clicks',\n",
      "       'questionnaire_clicks', 'page_clicks', 'externalquiz_clicks',\n",
      "       'ouwiki_clicks', 'dualpane_clicks', 'folder_clicks',\n",
      "       'repeatactivity_clicks', 'htmlactivity_clicks', 'assessment_type',\n",
      "       'weight', 'submission_delay'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_test=pd.read_csv(\"sets/X_test.csv\")\n",
    "X_train=pd.read_csv(\"sets/X_train.csv\")\n",
    "y_test=pd.read_csv(\"sets/y_test.csv\")['score']\n",
    "y_train=pd.read_csv(\"sets/y_train.csv\")['score']\n",
    "print(X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the amount of classes we wount to divide the target values into and reassigne the values in the target sets.\n",
    "\n",
    "Let $c$ be the number of classes, each value $v$, belonging to the set $V$ that we want to modify, will be reassigned as follows:\n",
    "\n",
    "$$\n",
    "v=\\left\\lceil\\frac{v-\\min{V}}{\\frac{\\max{V}-\\min{V}}{c}}\\right\\rceil\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=5\n",
    "\n",
    "def classesAssignment(nClasses, set, maximum, minimum):\n",
    "    \"\"\"\n",
    "    Modifies the set in input such that values will be rounded off to the corresponding class.\n",
    "     Args:\n",
    "     nClasses: the expected quantity of values\n",
    "     set: the set that has to be modified\n",
    "     maximum: the maximum possible value in the set\n",
    "     minimum: the minimum possible value in the set\n",
    "    \"\"\"\n",
    "\n",
    "    retSet=np.ceil((set-minimum)/((maximum-minimum)/nClasses))\n",
    "    \n",
    "    for i in range(len(retSet)) :\n",
    "        if retSet[i]==0 :\n",
    "            retSet[i]=1\n",
    "\n",
    "    return retSet\n",
    "\n",
    "\n",
    "maximum=max(y_test.max(),y_train.max())\n",
    "minimum=min(y_test.min(),y_train.min())\n",
    "\n",
    "y_test1=classesAssignment(classes,y_test,maximum,minimum)\n",
    "y_train1=classesAssignment(classes,y_train,maximum,minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gender', 'region', 'highest_education', 'imd_band', 'age_band',\n",
      "       'num_of_prev_attempts', 'studied_credits', 'disability',\n",
      "       'date_registration', 'forumng_clicks', 'homepage_clicks',\n",
      "       'oucontent_clicks', 'resource_clicks', 'subpage_clicks', 'url_clicks',\n",
      "       'dataplus_clicks', 'glossary_clicks', 'oucollaborate_clicks',\n",
      "       'quiz_clicks', 'ouelluminate_clicks', 'sharedsubpage_clicks',\n",
      "       'questionnaire_clicks', 'page_clicks', 'externalquiz_clicks',\n",
      "       'ouwiki_clicks', 'dualpane_clicks', 'folder_clicks',\n",
      "       'repeatactivity_clicks', 'htmlactivity_clicks', 'assessment_type',\n",
      "       'weight', 'submission_delay'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "lrm = skm.LogisticRegression(multi_class='ovr',max_iter=10000,random_state=2)\n",
    "\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000, multi_class=&#x27;ovr&#x27;, random_state=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, multi_class=&#x27;ovr&#x27;, random_state=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000, multi_class='ovr', random_state=2)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrm.fit(X_train,y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5065487483934146\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.00      0.00       506\n",
      "         2.0       0.00      0.00      0.00      1228\n",
      "         3.0       0.30      0.01      0.02      4477\n",
      "         4.0       0.45      0.54      0.49     12358\n",
      "         5.0       0.56      0.69      0.62     14109\n",
      "\n",
      "    accuracy                           0.51     32678\n",
      "   macro avg       0.46      0.25      0.23     32678\n",
      "weighted avg       0.47      0.51      0.46     32678\n",
      "\n",
      "Accuracy training: 0.5055275459226221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00      2033\n",
      "         2.0       0.06      0.00      0.00      5107\n",
      "         3.0       0.35      0.01      0.03     18013\n",
      "         4.0       0.45      0.54      0.49     49182\n",
      "         5.0       0.56      0.69      0.62     56374\n",
      "\n",
      "    accuracy                           0.51    130709\n",
      "   macro avg       0.28      0.25      0.23    130709\n",
      "weighted avg       0.46      0.51      0.45    130709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds=lrm.predict(X_test)\n",
    "\n",
    "check=preds==y_test1\n",
    "for i in range(len(check)):\n",
    "    if not check[i]:\n",
    "        continue\n",
    "        print (preds[i],y_test1[i])\n",
    "\n",
    "def perf_measure(y_actual, y_hat):\n",
    "   TP = 0\n",
    "   FP = 0\n",
    "   TN = 0\n",
    "   FN = 0\n",
    "\n",
    "   for i in range(len(y_hat)): \n",
    "      if y_actual[i]==y_hat[i]==1:\n",
    "         TP += 1\n",
    "      if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "         FP += 1\n",
    "      if y_actual[i]==y_hat[i]==0:\n",
    "        TN += 1\n",
    "      if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "        FN += 1\n",
    "   print(i)\n",
    "   return(TP, FP, TN, FN)\n",
    "\n",
    "accuracy=(sum(preds==y_test1))/len(preds)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test1, preds))\n",
    "\n",
    "preds_train=lrm.predict(X_train)\n",
    "check=preds_train==y_train1\n",
    "accuracy = accuracy_score(y_train1, preds_train)\n",
    "print(\"Accuracy training:\", accuracy)\n",
    "print(classification_report(y_train1, preds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1    0    2  365  138]\n",
      " [   0    0   27  768  433]\n",
      " [   0    0   53 2765 1659]\n",
      " [   0    3   74 6694 5587]\n",
      " [   0    1   19 4284 9805]]\n",
      "Selected Features: Index(['forumng_clicks', 'dataplus_clicks', 'questionnaire_clicks',\n",
      "       'ouwiki_clicks', 'assessment_type', 'weight', 'submission_delay'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test1, preds))\n",
    "#coefficients=lrm.coef_\n",
    "sfm = SelectFromModel(lrm, threshold=1e-0)\n",
    "sfm.fit(X_train, y_train1)\n",
    "\n",
    "# Selected features\n",
    "selected_features = X_train.columns[sfm.get_support()]\n",
    "\n",
    "# Display selected features\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m Xtrain\u001b[38;5;241m=\u001b[39mX_train[featuresC]\n\u001b[1;32m     17\u001b[0m lrm \u001b[38;5;241m=\u001b[39m skm\u001b[38;5;241m.\u001b[39mLogisticRegression(multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultinomial\u001b[39m\u001b[38;5;124m'\u001b[39m,max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m lrm\u001b[38;5;241m.\u001b[39mfit(Xtrain,y_train1)\n\u001b[1;32m     20\u001b[0m preds\u001b[38;5;241m=\u001b[39mlrm\u001b[38;5;241m.\u001b[39mpredict(Xtest)\n\u001b[1;32m     22\u001b[0m check\u001b[38;5;241m=\u001b[39mpreds\u001b[38;5;241m==\u001b[39my_test1\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1302\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1300\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1302\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, prefer\u001b[38;5;241m=\u001b[39mprefer)(\n\u001b[1;32m   1303\u001b[0m     path_func(\n\u001b[1;32m   1304\u001b[0m         X,\n\u001b[1;32m   1305\u001b[0m         y,\n\u001b[1;32m   1306\u001b[0m         pos_class\u001b[38;5;241m=\u001b[39mclass_,\n\u001b[1;32m   1307\u001b[0m         Cs\u001b[38;5;241m=\u001b[39m[C_],\n\u001b[1;32m   1308\u001b[0m         l1_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratio,\n\u001b[1;32m   1309\u001b[0m         fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept,\n\u001b[1;32m   1310\u001b[0m         tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[1;32m   1311\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m   1312\u001b[0m         solver\u001b[38;5;241m=\u001b[39msolver,\n\u001b[1;32m   1313\u001b[0m         multi_class\u001b[38;5;241m=\u001b[39mmulti_class,\n\u001b[1;32m   1314\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[1;32m   1315\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m   1316\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1317\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[1;32m   1318\u001b[0m         coef\u001b[38;5;241m=\u001b[39mwarm_start_coef_,\n\u001b[1;32m   1319\u001b[0m         penalty\u001b[38;5;241m=\u001b[39mpenalty,\n\u001b[1;32m   1320\u001b[0m         max_squared_sum\u001b[38;5;241m=\u001b[39mmax_squared_sum,\n\u001b[1;32m   1321\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1322\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[1;32m   1323\u001b[0m     )\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m class_, warm_start_coef_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(classes_, warm_start_coef)\n\u001b[1;32m   1325\u001b[0m )\n\u001b[1;32m   1327\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:452\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    448\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C\n\u001b[1;32m    449\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[1;32m    450\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[1;32m    451\u001b[0m ]\n\u001b[0;32m--> 452\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m optimize\u001b[38;5;241m.\u001b[39mminimize(\n\u001b[1;32m    453\u001b[0m     func,\n\u001b[1;32m    454\u001b[0m     w0,\n\u001b[1;32m    455\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL-BFGS-B\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    456\u001b[0m     jac\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    457\u001b[0m     args\u001b[38;5;241m=\u001b[39m(X, target, sample_weight, l2_reg_strength, n_threads),\n\u001b[1;32m    458\u001b[0m     options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miprint\u001b[39m\u001b[38;5;124m\"\u001b[39m: iprint, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgtol\u001b[39m\u001b[38;5;124m\"\u001b[39m: tol, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_iter},\n\u001b[1;32m    459\u001b[0m )\n\u001b[1;32m    460\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[1;32m    461\u001b[0m     solver,\n\u001b[1;32m    462\u001b[0m     opt_res,\n\u001b[1;32m    463\u001b[0m     max_iter,\n\u001b[1;32m    464\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[1;32m    465\u001b[0m )\n\u001b[1;32m    466\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_minimize.py:696\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    693\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    694\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 696\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m    697\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    699\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    700\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py:359\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    353\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m func_and_grad(x)\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl()\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_optimize.py:76\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     75\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_if_needed(x, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_optimize.py:70\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 70\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfun(x, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:298\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    296\u001b[0m grad[:, :n_features] \u001b[38;5;241m=\u001b[39m grad_pointwise\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m X \u001b[38;5;241m+\u001b[39m l2_reg_strength \u001b[38;5;241m*\u001b[39m weights\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept:\n\u001b[0;32m--> 298\u001b[0m     grad[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m grad_pointwise\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coef\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    300\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39mravel(order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features=[]\n",
    "\n",
    "for feature in X_test.columns:\n",
    "    features.append(feature)\n",
    "\n",
    "featuresC=features.copy()\n",
    "\n",
    "accMax=0\n",
    "accMin=200\n",
    "\n",
    "for feature in features:\n",
    "    #print(\"E' IL TURNO DELLA FEATURE \",feature)\n",
    "    featuresC.remove(feature)\n",
    "\n",
    "    Xtest=X_test[featuresC]\n",
    "    Xtrain=X_train[featuresC]\n",
    "    lrm = skm.LogisticRegression(multi_class='multinomial',max_iter=10000,random_state=2)\n",
    "    lrm.fit(Xtrain,y_train1)\n",
    "\n",
    "    preds=lrm.predict(Xtest)\n",
    "\n",
    "    check=preds==y_test1\n",
    "    accuracy = accuracy_score(y_test1, preds)\n",
    "   # print(\"Accuracy:\", accuracy)\n",
    "    #print(classification_report(y_test, preds))\n",
    "\n",
    "    if accuracy>accMax:\n",
    "        accMax=accuracy\n",
    "        featureMax=feature\n",
    "    if accuracy<accMin:\n",
    "        accMin=accuracy\n",
    "        featureMin=feature\n",
    "\n",
    "    featuresC.append(feature)    \n",
    "\n",
    "print(\"FeatureMax è: \",featureMax,\" con \",accMax)\n",
    "print(\"FeatureMin è: \",featureMin,\" con \",accMin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log for search of best set of features:\n",
    "\n",
    "1:\n",
    "    FeatureMax è:  forumng_clicks  con  0.31868535406083603  \n",
    "    FeatureMax è:  assessment_type  con  0.30681192239427135\n",
    "\n",
    "remove forumng_clicks\n",
    "\n",
    "2:\n",
    "    FeatureMax è:  studied_credits  con  0.3192667849929616  \n",
    "    FeatureMax è:  assessment_type  con  0.30616928820613254    \n",
    "\n",
    "remove studied_credits\n",
    "\n",
    "3:\n",
    "    FeatureMax è:  page_clicks  con  0.319787012669074   \n",
    "    FeatureMax è:  assessment_type  con  0.3072709468143705\n",
    "\n",
    "remove page_clicks\n",
    "\n",
    "4:\n",
    "    FeatureMax è:  dualpane_clicks  con  0.3201236305771467    \n",
    "    FeatureMax è:  assessment_type  con  0.3078523777464961\n",
    "\n",
    "remove dualpane_clicks\n",
    "\n",
    "5:\n",
    "    FeatureMax è:  num_of_prev_attempts  con  0.32021543546116654  \n",
    "    FeatureMax è:  assessment_type  con  0.30806658914254237\n",
    "\n",
    "remove num_of_prev_attempts\n",
    "\n",
    "6:  \n",
    "    FeatureMax è:  url_clicks  con  0.32021543546116654  \n",
    "    FeatureMax è:  assessment_type  con  0.30837260542260847\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROUND 2\n",
    "\n",
    "1:\n",
    "    FeatureMax è:  dataplus_clicks  con  0.3179509149886774  \n",
    "    FeatureMax è:  assessment_type  con  0.3084644103066283\n",
    "\n",
    "2:\n",
    "    FeatureMax è:  region  con  0.31807332150070383  \n",
    "FeatureMin è:  assessment_type  con  0.30803598751453576\n",
    "\n",
    "3:\n",
    "    FeatureMax è:  dualpane_clicks  con  0.3181957280127303  \n",
    "FeatureMin è:  assessment_type  con  0.30803598751453576\n",
    "\n",
    "4:\n",
    "    FeatureMax è:  disability  con  0.3182263296407369  \n",
    "FeatureMin è:  assessment_type  con  0.30806658914254237"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROUND 3\n",
    "\n",
    "1:FeatureMax è:  studied_credits  con  0.3115245731072893  \n",
    "FeatureMin è:  assessment_type  con  0.3017014505171675\n",
    "\n",
    "2:FeatureMax è:  submission_delay  con  0.3123508170634678  \n",
    "FeatureMin è:  assessment_type  con  0.3034151416855377\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Most of the runs give a result such as the following:\n",
    "\n",
    "Accuracy is:  0.32027663871717976\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         1.0       0.43      0.08      0.14       287\n",
    "         2.0       0.00      0.00      0.00       219\n",
    "         3.0       0.00      0.00      0.00       343\n",
    "         4.0       0.14      0.00      0.00       885\n",
    "         5.0       0.10      0.01      0.01      1368\n",
    "         6.0       0.21      0.01      0.02      3109\n",
    "         7.0       0.18      0.04      0.06      4508\n",
    "         8.0       0.27      0.43      0.33      7850\n",
    "         9.0       0.31      0.37      0.34      6808\n",
    "        10.0       0.41      0.59      0.48      7301\n",
    "\n",
    "    accuracy                           0.32     32678\n",
    "   macro avg       0.21      0.15      0.14     32678\n",
    "weighted avg       0.28      0.32      0.27     32678\n",
    "\n",
    "\n",
    "This approach didn't work really well. We can see that received an evaluation below 70 almost never get identifies. This is probably due to the fact that these student have less representation, compared to student that have recevied a score of more than 70. \n",
    "\n",
    "Let's try another approach: divide the students in classe, not solely based on their scores, but also based on how many students received a similar score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fairClassesAssignment(nClasses, set, maximum, minimum):\n",
    "    \"\"\"\n",
    "    Modifies the set in input such that values will be rounded off and divided in classes in a more\n",
    "    distributed (and approcimately fair) fashion.\n",
    "     Args:\n",
    "     nClasses: the expected quantity of values\n",
    "     set: the set that has to be modified\n",
    "     maximum: the maximum possible value in the set\n",
    "     minimum: the minimum possible value in the set\n",
    "    \"\"\"\n",
    "    set += np.abs(minimum)\n",
    "    retSet = np.zeros(len(set))\n",
    "\n",
    "    setIndex = sorted(list(zip(set,range(len(set)))))\n",
    "\n",
    "    binSize=len(set)/nClasses\n",
    "    \n",
    "    for i in range(len(set)):\n",
    "        retSet[setIndex[i][1]]=min((i//binSize)+1,nClasses)\n",
    "\n",
    "    return retSet\n",
    "\n",
    "\n",
    "maximum=max(y_test.max(),y_train.max())\n",
    "minimum=min(y_test.min(),y_train.min())\n",
    "\n",
    "y_test2=fairClassesAssignment(classes,y_test,maximum,minimum)\n",
    "y_train2=fairClassesAssignment(classes,y_train,maximum,minimum)\n",
    "\n",
    "stuff1=np.array([y_test,y_test2])\n",
    "stuff2=np.array([y_test,y_test2])\n",
    "for i in range(1,classes+1):\n",
    "    fstf1=stuff1[0, stuff1[1, :] == i]\n",
    "    fstf2=stuff2[0, stuff2[1, :] == i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that classes are balanced, let's try again logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3408409327376216\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.34      0.46      0.39      6536\n",
      "         2.0       0.28      0.26      0.27      6536\n",
      "         3.0       0.24      0.06      0.10      6535\n",
      "         4.0       0.34      0.36      0.35      6536\n",
      "         5.0       0.40      0.56      0.47      6535\n",
      "\n",
      "    accuracy                           0.34     32678\n",
      "   macro avg       0.32      0.34      0.32     32678\n",
      "weighted avg       0.32      0.34      0.32     32678\n",
      "\n",
      "Accuracy training: 0.34232531807297123\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.35      0.47      0.40     26142\n",
      "         2.0       0.28      0.26      0.27     26142\n",
      "         3.0       0.25      0.06      0.10     26142\n",
      "         4.0       0.34      0.35      0.34     26142\n",
      "         5.0       0.40      0.56      0.47     26141\n",
      "\n",
      "    accuracy                           0.34    130709\n",
      "   macro avg       0.32      0.34      0.32    130709\n",
      "weighted avg       0.32      0.34      0.32    130709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lrm = skm.LogisticRegression(multi_class='multinomial',max_iter=10000,random_state=2)\n",
    "\n",
    "lrm.fit(X_train,y_train2)\n",
    "\n",
    "preds=lrm.predict(X_test)\n",
    "\n",
    "check=preds==y_test2\n",
    "for i in range(len(check)):\n",
    "    if not check[i]:\n",
    "        continue\n",
    "        print (preds[i],y_test2[i])\n",
    "accuracy = accuracy_score(y_test2, preds)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test2, preds))\n",
    "\n",
    "preds_train=lrm.predict(X_train)\n",
    "check=preds_train==y_train2\n",
    "accuracy = accuracy_score(y_train2, preds_train)\n",
    "print(\"Accuracy training:\", accuracy)\n",
    "print(classification_report(y_train2, preds_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN WITH INITIAL DISTRIBUTION GRID SEARCH\n",
    "result: useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "solver= newton-cg penalty= l2 value= 100\n",
      "Accuracy: 0.5051716751331171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.00      0.00       506\n",
      "         2.0       0.11      0.00      0.00      1228\n",
      "         3.0       0.33      0.02      0.03      4477\n",
      "         4.0       0.45      0.56      0.50     12358\n",
      "         5.0       0.56      0.67      0.61     14109\n",
      "\n",
      "    accuracy                           0.51     32678\n",
      "   macro avg       0.49      0.25      0.23     32678\n",
      "weighted avg       0.48      0.51      0.46     32678\n",
      "\n",
      "Accuracy training: 0.5042116457168213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.17      0.00      0.00      2033\n",
      "         2.0       0.05      0.00      0.00      5107\n",
      "         3.0       0.35      0.02      0.04     18013\n",
      "         4.0       0.45      0.56      0.50     49182\n",
      "         5.0       0.56      0.67      0.61     56374\n",
      "\n",
      "    accuracy                           0.50    130709\n",
      "   macro avg       0.31      0.25      0.23    130709\n",
      "weighted avg       0.46      0.50      0.46    130709\n",
      "\n",
      "-------------------------------------------\n",
      "solver= newton-cg penalty= l2 value= 10\n",
      "Accuracy: 0.5051716751331171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.00      0.00       506\n",
      "         2.0       0.11      0.00      0.00      1228\n",
      "         3.0       0.33      0.02      0.03      4477\n",
      "         4.0       0.45      0.56      0.50     12358\n",
      "         5.0       0.56      0.67      0.61     14109\n",
      "\n",
      "    accuracy                           0.51     32678\n",
      "   macro avg       0.49      0.25      0.23     32678\n",
      "weighted avg       0.48      0.51      0.46     32678\n",
      "\n",
      "Accuracy training: 0.5042116457168213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.17      0.00      0.00      2033\n",
      "         2.0       0.05      0.00      0.00      5107\n",
      "         3.0       0.35      0.02      0.04     18013\n",
      "         4.0       0.45      0.56      0.50     49182\n",
      "         5.0       0.56      0.67      0.61     56374\n",
      "\n",
      "    accuracy                           0.50    130709\n",
      "   macro avg       0.31      0.25      0.23    130709\n",
      "weighted avg       0.46      0.50      0.46    130709\n",
      "\n",
      "-------------------------------------------\n",
      "solver= newton-cg penalty= l2 value= 1.0\n",
      "Accuracy: 0.5051716751331171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.00      0.00       506\n",
      "         2.0       0.11      0.00      0.00      1228\n",
      "         3.0       0.33      0.02      0.03      4477\n",
      "         4.0       0.45      0.56      0.50     12358\n",
      "         5.0       0.56      0.67      0.61     14109\n",
      "\n",
      "    accuracy                           0.51     32678\n",
      "   macro avg       0.49      0.25      0.23     32678\n",
      "weighted avg       0.48      0.51      0.46     32678\n",
      "\n",
      "Accuracy training: 0.5042116457168213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.20      0.00      0.00      2033\n",
      "         2.0       0.05      0.00      0.00      5107\n",
      "         3.0       0.35      0.02      0.04     18013\n",
      "         4.0       0.45      0.56      0.50     49182\n",
      "         5.0       0.56      0.67      0.61     56374\n",
      "\n",
      "    accuracy                           0.50    130709\n",
      "   macro avg       0.32      0.25      0.23    130709\n",
      "weighted avg       0.46      0.50      0.46    130709\n",
      "\n",
      "-------------------------------------------\n",
      "solver= newton-cg penalty= l2 value= 0.1\n",
      "Accuracy: 0.5051716751331171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.00      0.00       506\n",
      "         2.0       0.11      0.00      0.00      1228\n",
      "         3.0       0.32      0.02      0.03      4477\n",
      "         4.0       0.45      0.56      0.50     12358\n",
      "         5.0       0.56      0.67      0.61     14109\n",
      "\n",
      "    accuracy                           0.51     32678\n",
      "   macro avg       0.49      0.25      0.23     32678\n",
      "weighted avg       0.48      0.51      0.46     32678\n",
      "\n",
      "Accuracy training: 0.5042192962994132\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.20      0.00      0.00      2033\n",
      "         2.0       0.05      0.00      0.00      5107\n",
      "         3.0       0.35      0.02      0.03     18013\n",
      "         4.0       0.45      0.56      0.50     49182\n",
      "         5.0       0.56      0.67      0.61     56374\n",
      "\n",
      "    accuracy                           0.50    130709\n",
      "   macro avg       0.32      0.25      0.23    130709\n",
      "weighted avg       0.46      0.50      0.46    130709\n",
      "\n",
      "-------------------------------------------\n",
      "solver= newton-cg penalty= l2 value= 0.01\n",
      "Accuracy: 0.5048962604810576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       506\n",
      "         2.0       0.00      0.00      0.00      1228\n",
      "         3.0       0.32      0.02      0.03      4477\n",
      "         4.0       0.45      0.56      0.50     12358\n",
      "         5.0       0.56      0.67      0.61     14109\n",
      "\n",
      "    accuracy                           0.50     32678\n",
      "   macro avg       0.27      0.25      0.23     32678\n",
      "weighted avg       0.45      0.50      0.46     32678\n",
      "\n",
      "Accuracy training: 0.5042728503775562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00      2033\n",
      "         2.0       0.06      0.00      0.00      5107\n",
      "         3.0       0.35      0.02      0.03     18013\n",
      "         4.0       0.45      0.56      0.50     49182\n",
      "         5.0       0.56      0.67      0.61     56374\n",
      "\n",
      "    accuracy                           0.50    130709\n",
      "   macro avg       0.28      0.25      0.23    130709\n",
      "weighted avg       0.46      0.50      0.46    130709\n",
      "\n",
      "-------------------------------------------\n",
      "solver= lbfgs penalty= l2 value= 100\n",
      "Accuracy: 0.5051410735051105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.00      0.00       506\n",
      "         2.0       0.11      0.00      0.00      1228\n",
      "         3.0       0.33      0.02      0.03      4477\n",
      "         4.0       0.45      0.56      0.50     12358\n",
      "         5.0       0.56      0.67      0.61     14109\n",
      "\n",
      "    accuracy                           0.51     32678\n",
      "   macro avg       0.49      0.25      0.23     32678\n",
      "weighted avg       0.48      0.51      0.46     32678\n",
      "\n",
      "Accuracy training: 0.5042192962994132\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.20      0.00      0.00      2033\n",
      "         2.0       0.05      0.00      0.00      5107\n",
      "         3.0       0.35      0.02      0.04     18013\n",
      "         4.0       0.45      0.56      0.50     49182\n",
      "         5.0       0.56      0.67      0.61     56374\n",
      "\n",
      "    accuracy                           0.50    130709\n",
      "   macro avg       0.32      0.25      0.23    130709\n",
      "weighted avg       0.46      0.50      0.46    130709\n",
      "\n",
      "-------------------------------------------\n",
      "solver= lbfgs penalty= l2 value= 10\n",
      "Accuracy: 0.5052022767611237\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.00      0.00       506\n",
      "         2.0       0.11      0.00      0.00      1228\n",
      "         3.0       0.33      0.02      0.03      4477\n",
      "         4.0       0.45      0.56      0.50     12358\n",
      "         5.0       0.56      0.67      0.61     14109\n",
      "\n",
      "    accuracy                           0.51     32678\n",
      "   macro avg       0.49      0.25      0.23     32678\n",
      "weighted avg       0.48      0.51      0.46     32678\n",
      "\n",
      "Accuracy training: 0.5042039951342294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.20      0.00      0.00      2033\n",
      "         2.0       0.05      0.00      0.00      5107\n",
      "         3.0       0.35      0.02      0.03     18013\n",
      "         4.0       0.45      0.56      0.50     49182\n",
      "         5.0       0.56      0.67      0.61     56374\n",
      "\n",
      "    accuracy                           0.50    130709\n",
      "   macro avg       0.32      0.25      0.23    130709\n",
      "weighted avg       0.46      0.50      0.46    130709\n",
      "\n",
      "-------------------------------------------\n",
      "solver= lbfgs penalty= l2 value= 1.0\n",
      "Accuracy: 0.5052022767611237\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.00      0.00       506\n",
      "         2.0       0.11      0.00      0.00      1228\n",
      "         3.0       0.33      0.02      0.03      4477\n",
      "         4.0       0.45      0.56      0.50     12358\n",
      "         5.0       0.56      0.67      0.61     14109\n",
      "\n",
      "    accuracy                           0.51     32678\n",
      "   macro avg       0.49      0.25      0.23     32678\n",
      "weighted avg       0.48      0.51      0.46     32678\n",
      "\n",
      "Accuracy training: 0.5042116457168213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.20      0.00      0.00      2033\n",
      "         2.0       0.05      0.00      0.00      5107\n",
      "         3.0       0.35      0.02      0.04     18013\n",
      "         4.0       0.45      0.56      0.50     49182\n",
      "         5.0       0.56      0.67      0.61     56374\n",
      "\n",
      "    accuracy                           0.50    130709\n",
      "   macro avg       0.32      0.25      0.23    130709\n",
      "weighted avg       0.46      0.50      0.46    130709\n",
      "\n",
      "-------------------------------------------\n",
      "solver= lbfgs penalty= l2 value= 0.1\n",
      "Accuracy: 0.5051716751331171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.00      0.00       506\n",
      "         2.0       0.11      0.00      0.00      1228\n",
      "         3.0       0.32      0.02      0.03      4477\n",
      "         4.0       0.45      0.56      0.50     12358\n",
      "         5.0       0.56      0.67      0.61     14109\n",
      "\n",
      "    accuracy                           0.51     32678\n",
      "   macro avg       0.49      0.25      0.23     32678\n",
      "weighted avg       0.48      0.51      0.46     32678\n",
      "\n",
      "Accuracy training: 0.504234597464597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.20      0.00      0.00      2033\n",
      "         2.0       0.05      0.00      0.00      5107\n",
      "         3.0       0.35      0.02      0.03     18013\n",
      "         4.0       0.45      0.56      0.50     49182\n",
      "         5.0       0.56      0.67      0.61     56374\n",
      "\n",
      "    accuracy                           0.50    130709\n",
      "   macro avg       0.32      0.25      0.23    130709\n",
      "weighted avg       0.46      0.50      0.46    130709\n",
      "\n",
      "-------------------------------------------\n",
      "solver= lbfgs penalty= l2 value= 0.01\n",
      "Accuracy: 0.5049268621090642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       506\n",
      "         2.0       0.00      0.00      0.00      1228\n",
      "         3.0       0.32      0.02      0.03      4477\n",
      "         4.0       0.45      0.56      0.50     12358\n",
      "         5.0       0.56      0.67      0.61     14109\n",
      "\n",
      "    accuracy                           0.50     32678\n",
      "   macro avg       0.26      0.25      0.23     32678\n",
      "weighted avg       0.45      0.50      0.46     32678\n",
      "\n",
      "Accuracy training: 0.5042651997949644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00      2033\n",
      "         2.0       0.06      0.00      0.00      5107\n",
      "         3.0       0.35      0.02      0.03     18013\n",
      "         4.0       0.45      0.56      0.50     49182\n",
      "         5.0       0.56      0.67      0.61     56374\n",
      "\n",
      "    accuracy                           0.50    130709\n",
      "   macro avg       0.28      0.25      0.23    130709\n",
      "weighted avg       0.46      0.50      0.46    130709\n",
      "\n",
      "-------------------------------------------\n",
      "solver= saga penalty= l2 value= 100\n",
      "Accuracy: 0.5051716751331171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.00      0.00       506\n",
      "         2.0       0.11      0.00      0.00      1228\n",
      "         3.0       0.33      0.02      0.03      4477\n",
      "         4.0       0.45      0.56      0.50     12358\n",
      "         5.0       0.56      0.67      0.61     14109\n",
      "\n",
      "    accuracy                           0.51     32678\n",
      "   macro avg       0.49      0.25      0.23     32678\n",
      "weighted avg       0.48      0.51      0.46     32678\n",
      "\n",
      "Accuracy training: 0.5042039951342294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.17      0.00      0.00      2033\n",
      "         2.0       0.05      0.00      0.00      5107\n",
      "         3.0       0.35      0.02      0.04     18013\n",
      "         4.0       0.45      0.56      0.50     49182\n",
      "         5.0       0.56      0.67      0.61     56374\n",
      "\n",
      "    accuracy                           0.50    130709\n",
      "   macro avg       0.31      0.25      0.23    130709\n",
      "weighted avg       0.46      0.50      0.46    130709\n",
      "\n",
      "-------------------------------------------\n",
      "solver= saga penalty= l2 value= 10\n",
      "Accuracy: 0.5051716751331171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.00      0.00       506\n",
      "         2.0       0.11      0.00      0.00      1228\n",
      "         3.0       0.33      0.02      0.03      4477\n",
      "         4.0       0.45      0.56      0.50     12358\n",
      "         5.0       0.56      0.67      0.61     14109\n",
      "\n",
      "    accuracy                           0.51     32678\n",
      "   macro avg       0.49      0.25      0.23     32678\n",
      "weighted avg       0.48      0.51      0.46     32678\n",
      "\n",
      "Accuracy training: 0.5042039951342294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.17      0.00      0.00      2033\n",
      "         2.0       0.05      0.00      0.00      5107\n",
      "         3.0       0.35      0.02      0.04     18013\n",
      "         4.0       0.45      0.56      0.50     49182\n",
      "         5.0       0.56      0.67      0.61     56374\n",
      "\n",
      "    accuracy                           0.50    130709\n",
      "   macro avg       0.31      0.25      0.23    130709\n",
      "weighted avg       0.46      0.50      0.46    130709\n",
      "\n",
      "-------------------------------------------\n",
      "solver= saga penalty= l2 value= 1.0\n",
      "Accuracy: 0.5051716751331171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.00      0.00       506\n",
      "         2.0       0.11      0.00      0.00      1228\n",
      "         3.0       0.33      0.02      0.03      4477\n",
      "         4.0       0.45      0.56      0.50     12358\n",
      "         5.0       0.56      0.67      0.61     14109\n",
      "\n",
      "    accuracy                           0.51     32678\n",
      "   macro avg       0.49      0.25      0.23     32678\n",
      "weighted avg       0.48      0.51      0.46     32678\n",
      "\n",
      "Accuracy training: 0.5042116457168213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.20      0.00      0.00      2033\n",
      "         2.0       0.05      0.00      0.00      5107\n",
      "         3.0       0.35      0.02      0.04     18013\n",
      "         4.0       0.45      0.56      0.50     49182\n",
      "         5.0       0.56      0.67      0.61     56374\n",
      "\n",
      "    accuracy                           0.50    130709\n",
      "   macro avg       0.32      0.25      0.23    130709\n",
      "weighted avg       0.46      0.50      0.46    130709\n",
      "\n",
      "-------------------------------------------\n",
      "solver= saga penalty= l2 value= 0.1\n",
      "Accuracy: 0.5052022767611237\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.00      0.00       506\n",
      "         2.0       0.11      0.00      0.00      1228\n",
      "         3.0       0.32      0.02      0.03      4477\n",
      "         4.0       0.45      0.56      0.50     12358\n",
      "         5.0       0.56      0.67      0.61     14109\n",
      "\n",
      "    accuracy                           0.51     32678\n",
      "   macro avg       0.49      0.25      0.23     32678\n",
      "weighted avg       0.48      0.51      0.46     32678\n",
      "\n",
      "Accuracy training: 0.5042116457168213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.20      0.00      0.00      2033\n",
      "         2.0       0.05      0.00      0.00      5107\n",
      "         3.0       0.35      0.02      0.03     18013\n",
      "         4.0       0.45      0.56      0.50     49182\n",
      "         5.0       0.56      0.67      0.61     56374\n",
      "\n",
      "    accuracy                           0.50    130709\n",
      "   macro avg       0.32      0.25      0.23    130709\n",
      "weighted avg       0.46      0.50      0.46    130709\n",
      "\n",
      "-------------------------------------------\n",
      "solver= saga penalty= l2 value= 0.01\n",
      "Accuracy: 0.5048962604810576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       506\n",
      "         2.0       0.00      0.00      0.00      1228\n",
      "         3.0       0.32      0.02      0.03      4477\n",
      "         4.0       0.45      0.56      0.50     12358\n",
      "         5.0       0.56      0.67      0.61     14109\n",
      "\n",
      "    accuracy                           0.50     32678\n",
      "   macro avg       0.27      0.25      0.23     32678\n",
      "weighted avg       0.45      0.50      0.46     32678\n",
      "\n",
      "Accuracy training: 0.5042728503775562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00      2033\n",
      "         2.0       0.06      0.00      0.00      5107\n",
      "         3.0       0.35      0.02      0.03     18013\n",
      "         4.0       0.45      0.56      0.50     49182\n",
      "         5.0       0.56      0.67      0.61     56374\n",
      "\n",
      "    accuracy                           0.50    130709\n",
      "   macro avg       0.28      0.25      0.23    130709\n",
      "weighted avg       0.46      0.50      0.46    130709\n",
      "\n",
      "-------------------------------------------\n",
      "solver= sag penalty= l2 value= 100\n",
      "Accuracy: 0.5051716751331171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.00      0.00       506\n",
      "         2.0       0.11      0.00      0.00      1228\n",
      "         3.0       0.33      0.02      0.03      4477\n",
      "         4.0       0.45      0.56      0.50     12358\n",
      "         5.0       0.56      0.67      0.61     14109\n",
      "\n",
      "    accuracy                           0.51     32678\n",
      "   macro avg       0.49      0.25      0.23     32678\n",
      "weighted avg       0.48      0.51      0.46     32678\n",
      "\n",
      "Accuracy training: 0.5042039951342294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.17      0.00      0.00      2033\n",
      "         2.0       0.05      0.00      0.00      5107\n",
      "         3.0       0.35      0.02      0.04     18013\n",
      "         4.0       0.45      0.56      0.50     49182\n",
      "         5.0       0.56      0.67      0.61     56374\n",
      "\n",
      "    accuracy                           0.50    130709\n",
      "   macro avg       0.31      0.25      0.23    130709\n",
      "weighted avg       0.46      0.50      0.46    130709\n",
      "\n",
      "-------------------------------------------\n",
      "solver= sag penalty= l2 value= 10\n",
      "Accuracy: 0.5051716751331171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.00      0.00       506\n",
      "         2.0       0.11      0.00      0.00      1228\n",
      "         3.0       0.33      0.02      0.03      4477\n",
      "         4.0       0.45      0.56      0.50     12358\n",
      "         5.0       0.56      0.67      0.61     14109\n",
      "\n",
      "    accuracy                           0.51     32678\n",
      "   macro avg       0.49      0.25      0.23     32678\n",
      "weighted avg       0.48      0.51      0.46     32678\n",
      "\n",
      "Accuracy training: 0.5042039951342294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.17      0.00      0.00      2033\n",
      "         2.0       0.05      0.00      0.00      5107\n",
      "         3.0       0.35      0.02      0.04     18013\n",
      "         4.0       0.45      0.56      0.50     49182\n",
      "         5.0       0.56      0.67      0.61     56374\n",
      "\n",
      "    accuracy                           0.50    130709\n",
      "   macro avg       0.31      0.25      0.23    130709\n",
      "weighted avg       0.46      0.50      0.46    130709\n",
      "\n",
      "-------------------------------------------\n",
      "solver= sag penalty= l2 value= 1.0\n",
      "Accuracy: 0.5051716751331171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.00      0.00       506\n",
      "         2.0       0.11      0.00      0.00      1228\n",
      "         3.0       0.33      0.02      0.03      4477\n",
      "         4.0       0.45      0.56      0.50     12358\n",
      "         5.0       0.56      0.67      0.61     14109\n",
      "\n",
      "    accuracy                           0.51     32678\n",
      "   macro avg       0.49      0.25      0.23     32678\n",
      "weighted avg       0.48      0.51      0.46     32678\n",
      "\n",
      "Accuracy training: 0.5042116457168213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.20      0.00      0.00      2033\n",
      "         2.0       0.05      0.00      0.00      5107\n",
      "         3.0       0.35      0.02      0.04     18013\n",
      "         4.0       0.45      0.56      0.50     49182\n",
      "         5.0       0.56      0.67      0.61     56374\n",
      "\n",
      "    accuracy                           0.50    130709\n",
      "   macro avg       0.32      0.25      0.23    130709\n",
      "weighted avg       0.46      0.50      0.46    130709\n",
      "\n",
      "-------------------------------------------\n",
      "solver= sag penalty= l2 value= 0.1\n",
      "Accuracy: 0.5051716751331171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.00      0.00       506\n",
      "         2.0       0.11      0.00      0.00      1228\n",
      "         3.0       0.32      0.02      0.03      4477\n",
      "         4.0       0.45      0.56      0.50     12358\n",
      "         5.0       0.56      0.67      0.61     14109\n",
      "\n",
      "    accuracy                           0.51     32678\n",
      "   macro avg       0.49      0.25      0.23     32678\n",
      "weighted avg       0.48      0.51      0.46     32678\n",
      "\n",
      "Accuracy training: 0.5042192962994132\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.20      0.00      0.00      2033\n",
      "         2.0       0.05      0.00      0.00      5107\n",
      "         3.0       0.35      0.02      0.03     18013\n",
      "         4.0       0.45      0.56      0.50     49182\n",
      "         5.0       0.56      0.67      0.61     56374\n",
      "\n",
      "    accuracy                           0.50    130709\n",
      "   macro avg       0.32      0.25      0.23    130709\n",
      "weighted avg       0.46      0.50      0.46    130709\n",
      "\n",
      "-------------------------------------------\n",
      "solver= sag penalty= l2 value= 0.01\n",
      "Accuracy: 0.5048962604810576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       506\n",
      "         2.0       0.00      0.00      0.00      1228\n",
      "         3.0       0.32      0.02      0.03      4477\n",
      "         4.0       0.45      0.56      0.50     12358\n",
      "         5.0       0.56      0.67      0.61     14109\n",
      "\n",
      "    accuracy                           0.50     32678\n",
      "   macro avg       0.27      0.25      0.23     32678\n",
      "weighted avg       0.45      0.50      0.46     32678\n",
      "\n",
      "Accuracy training: 0.5042728503775562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00      2033\n",
      "         2.0       0.06      0.00      0.00      5107\n",
      "         3.0       0.35      0.02      0.03     18013\n",
      "         4.0       0.45      0.56      0.50     49182\n",
      "         5.0       0.56      0.67      0.61     56374\n",
      "\n",
      "    accuracy                           0.50    130709\n",
      "   macro avg       0.28      0.25      0.23    130709\n",
      "weighted avg       0.46      0.50      0.46    130709\n",
      "\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tolatale/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Solver liblinear does not support a multinomial backend.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m lrm \u001b[38;5;241m=\u001b[39m skm\u001b[38;5;241m.\u001b[39mLogisticRegression(multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultinomial\u001b[39m\u001b[38;5;124m'\u001b[39m,max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,solver\u001b[38;5;241m=\u001b[39msolver,\n\u001b[1;32m     10\u001b[0m                              penalty\u001b[38;5;241m=\u001b[39mpen,C\u001b[38;5;241m=\u001b[39mvalue)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m lrm\u001b[38;5;241m.\u001b[39mfit(X_train,y_train1)\n\u001b[1;32m     13\u001b[0m preds\u001b[38;5;241m=\u001b[39mlrm\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     14\u001b[0m check\u001b[38;5;241m=\u001b[39mpreds\u001b[38;5;241m==\u001b[39my_test1\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1218\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n\u001b[0;32m-> 1218\u001b[0m multi_class \u001b[38;5;241m=\u001b[39m _check_multi_class(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class, solver, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_))\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:92\u001b[0m, in \u001b[0;36m_check_multi_class\u001b[0;34m(multi_class, solver, n_classes)\u001b[0m\n\u001b[1;32m     90\u001b[0m         multi_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultinomial\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m solver \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnewton-cholesky\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolver \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not support a multinomial backend.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m solver)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m multi_class\n",
      "\u001b[0;31mValueError\u001b[0m: Solver liblinear does not support a multinomial backend."
     ]
    }
   ],
   "source": [
    "solvers = ['newton-cg', 'lbfgs', 'saga','sag','liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "\n",
    "# summarize results\n",
    "for solver in solvers:\n",
    "    for pen in penalty:\n",
    "        for value in c_values:\n",
    "            lrm = skm.LogisticRegression(multi_class='multinomial',max_iter=10000,random_state=2,solver=solver,\n",
    "                                         penalty=pen,C=value)\n",
    "            print(\"-------------------------------------------\")\n",
    "            lrm.fit(X_train,y_train1)\n",
    "            preds=lrm.predict(X_test)\n",
    "            check=preds==y_test1\n",
    "            print(\"solver=\",solver,\"penalty=\",pen,\"value=\",value)\n",
    "            accuracy = accuracy_score(y_test1, preds)\n",
    "            print(\"Accuracy:\", accuracy)\n",
    "            print(classification_report(y_test1, preds))\n",
    "\n",
    "            preds_train=lrm.predict(X_train)\n",
    "            check=preds_train==y_train1\n",
    "            accuracy = accuracy_score(y_train1, preds_train)\n",
    "            print(\"Accuracy training:\", accuracy)\n",
    "            print(classification_report(y_train1, preds_train))\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    \n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HYPOTHESIS FOR USEFUL FEATURES:\n",
    "\n",
    "-assessment_type\n",
    "\n",
    "-highest education\n",
    "\n",
    "-weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "IDEAS\n",
    "\n",
    "show a map of most influential features compared to grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
